\section{Complexity in Languages\timeestimation{30h}}
\label{sec:complexity}
While most languages we encounter are turing-complete, that does not need
to be the case. In this chapter, we will discuss the notion of a problem 
description as a programming language.

\subsection{Problem descriptions}
There are many different kinds of problems in computer science, for example 
sorting a list or determining if a boolean formula with variables is always
true. Nevertheless, these kind of problems are never singular -- we would not 
want an algorithm\footnote{Most definitions would not even allow this as an 
algorithm}, that could reliably sort the list $4, 8, 2, -9$, but one that 
could sort {\em all} lists, no matter the size. This means of course, that 
algorithms need data as input to describe the problems they need to solve. 
This data is then called the {\em problem description}. 

Looking back at the beginning, the semantic function was introduced to give 
meaning to data. Since then, we primarily used it to differentiate between 
\WHILE programs and the functions they denote. In the case of problem
descriptions, we can the interpretation of a problem would be the solution 
that we would expect. 

\begin{example}
	$U = Cons(Nil, Cons(Nil, Cons(Nil, Nil)))$, then $\interpret[unary]{U} = 3$.
\end{example}
\begin{example}
	$L=Cons(4, Cons(8, Cons(2, Cons(-9, Nil))))$ is the problem description for
	sorting the list $4, 8, 2, -9$ if given to a sorting procedure, formally
	$\interpret[sort]{L}= Cons(-9, Cons(2, Cons(4, Cons(8, Nil))))$. When given
	to a procedure, that calculates the minimum, the interpretation would be that
	instead, so $\interpret[min]{L} = -9$.
\end{example}

\lineofthought{Partial evaluation for partial problem descriptions?}
\TODO
\subsection{Reductions}
\TODO

\subsection{Hardness and completeness}
\TODO

\lineofthought{
	The closest connection might be Prolog, in which I state a problem 
	description, and the system will figure out a solution. Prolog is Turing 
	complete, but that stems from the fact that first order predicate 
	logic is.

	\begin{description}
		\item[$A$ reduces to $B$] $\exists\Compiler[\WHILE]{A}{B}\in P$
		\item[$a$ solves $P$] $\interpret[\WHILE]{a}(p.x)=\interpret[P]{p}(x)$
		\item[$f: P\rightarrow Partition(P)$ parametrizes $P$] 
			$\interpret{a}\circ f\in \PTIME$
	\end{description}

	Reductions are then cross compilations, algorithms are interpreter in the 
	hosting language. It all fits together nicely. I could even add 
	parametrizations as specializations, that massively reduce the complexity 
	necessary for an interpreter.
}

%and in fact some non-turing-complete languages have very
%interesting properties. In this chapter, I'll discuss some variations of
%the languages seen so far that relate to special classes of complexity and
%the notion of being complex relative to a language.
%\subsection{Complexity by Dialect} % (fold)
%\label{sub:Complexity by Dialect}
%\subsubsection{$P$ complexity} % (fold)
%\label{ssub:P-complexity}

%% subsubsection P-complexity (end)
%\subsubsection{$NP$ complexity} % (fold)
%\label{ssub:NP-complexity}

%% subsubsection NP-complexity (end)
%\subsubsection{An intrinsic view of $P \neq NP$} % (fold)
%\label{ssub:intrinsicPNP}
%\lineofthought{
  %Um zu zeigen, dass $NP \neq P$ ist, muss nun gezeigt werden, dass sich das 
  %Kommando {\tt CHOICE} nicht in die $P$ Sprache übersetzen lässt.
%}

%% subsubsection P neq NP
%% subsection Complexity by Dialect (end)
