\section{Self Interpretation\timeestimation{15h}}
\label{sec:self}
Self interpretation is the ability of an formalism to support an
"universal mechanism", that is a program that can interpret a finite
description of any programs in itself and apply it to some input.

For computability, self interpretation can be seen as some kind of gold
standard. This stems from the fact, that the simpler model of
computation, \FOR, are not self interpreting, which changes as soon as self interpretation is added.

\subsection{Recursion Theorem}
\begin{theorem}[Recursion Theorem]
	For any procedure $p\in \WHILE$ there is a procedure $p'\in \WHILE$ so 
	that $\interpret{p'}(x) = \interpret{p}(p'.x)$. This can uniformly be 
	computed by $Y\in \WHILE$, i.e. $\interpret{\interpret{Y}(p)}(x) = \interpret{p}(\interpret{Y}(p).x)$

	Every procedure of $\WHILE$ might as well use its own source code.
\end{theorem}
\begin{proof}
	Instead of giving $Y$ and explaining how it works, here is how one could 
	figure out how to do it\footnote{The proof here is based on \cite{dalenrecursion}}:

	\begin{enumerate}
		\item We start with $\interpret{h}(x):\peq \interpret{spec}(x.x)$, 
			because that gives us 
			\begin{equation*}
				\begin{split}
					\interpret{\interpret{h}(f)}(x)
					&\peq \interpret{\interpret{spec}(f.f)}(x)\\
					&\peq \interpret{f}(f.x)
				\end{split}
			\end{equation*}
			a procedure, that passes a given function as the first argument to 
			itself. This is not the full solution though: It uses the original 
			procedure $f$, not the transformed $\interpret{h}(f)$. Unfortunately, 
			we can't just write 
			$\interpret{h'}(x):\peq \interpret{spec}(x.\interpret{h}(x))$, because 
			that would give the same problem. 
		\item Instead we need to repeat this process 
			$\interpret{iterate\mhyphen combinator}(combinator.program.x):\peq 
			\interpret{program}(\interpret{spec}(combinator.(combinator.program)).x)$. 
			What does this do? We run the program and pass as its first argument 
			the code of a program that is modified by the combinator once. This is 
			basically the step from above, only for $combinator$.

			\begin{equation*}
				\begin{split}
					\interpret{iterate\mhyphen combinator}(c.program.x)
					&\peq \interpret{program}(\interpret{spec}(c.c.program).x) \\
					&\text{and to get the own source}\\
					\interpret{\interpret{spec}(c.c.program)}(x)
					&\overset{!}{\peq} \interpret{iterate\mhyphen combinator}(c.program.x)
				\end{split}
			\end{equation*}
		\item From the equation above, we can see, that we need to wrap
			$iterate\mhyphen combinator$ onto itself, 
			$\interpret{Y}(program):\peq \interpret{spec}(iterate\mhyphen
			combinator.(iterate\mhyphen combinator.program))$. 

			This has the desired property:

			\begin{equation*}
				\begin{split}
					\interpret{\interpret{Y}(program)}(x) 
					&\peq \interpret{\interpret{spec}(iterate\mhyphen
				combinator.(iterate\mhyphen combinator.program))}(x)\\
				&\peq \interpret{iterate\mhyphen combinator}(iterate\mhyphen combinator.program.x) \\
				&\peq \interpret{p}(\interpret{spec}(iterate\mhyphen combinator.iterate\mhyphen combinator.program).x)\\
				&\peq \interpret{p}(\interpret{Y}(program).x)
				\end{split}
			\end{equation*}
	\end{enumerate}
\end{proof}

\begin{example}[Quines]
	A \emph{quine}\/ is a program, that outputs its own source. It is a fun 
	exercise for all students of computer science to find a quine in their 
	favourite language. The existence of quines is ensured by the recursion theorem:
	Simply take the program $\interpret{id}(x)\peq x$ and then 
	$\interpret{\interpret{Y}(id)}() \peq \interpret{id}(\interpret{Y}(id))$ 
	is a quine.

	This is unfortunately not how you program a quine. Few languages have a $Y$ 
	procedure, and even if they had, they would use an own internal 
	representation for the $program$ and not the source code. To program 
	a quine, you have to execute the steps of $Y$ by hand. Because \WHILE does 
	not handle strings, it might not be the best choice to implement the quine, 
	so the following is written in {\tt Python}, but the same principle could 
	easily be applied to create a quine for other languages as well.

	\begin{enumerate}
		\item We basically need to return $\interpret{id}(id)$ as a string, but 
			in most languages, it's actually the other way around -- we define a 
			function and can decide to code it (as a string). That is commonly 
			denoted $id(\coded{id})$.
		\item So let's define a function, that does the coding:
\begin{verbatim}
def quote(source):
  return '"'*3 + source + '"'*3
\end{verbatim}
		\item Next, define a procedure, that prints its argument once without 
			quotes, once with the quotes, so basically the literal string ${\tt id(\coded{id})}$.
\begin{verbatim}
def quined(source):
  print source + '(' + quoted(source) + ')'
\end{verbatim}
		\item Finally, we can pass the source of the program to itself:
\begin{verbatim}

def quote(source):
  return '"'*3+source+'"'*3
def quined(source):
  print source + '(' + quote(source) +')'

quined("""
def quote(source):
  return '"'*3+source+'"'*3
def quined(source):
  print source + '(' + quote(source) +')'

quined""")
\end{verbatim}
		This recipe can be ported to many languages, including {\tt C}, {\tt Java} or {\tt Haskell}.
	\end{enumerate}
\end{example}

\paragraph{Why is it called the \emph{recursion} theorem?}
Since we have our own source, we can implement recursion with our interpreter:
\begin{verbatim}
fibonacci read (source.X) {
  if ([or](X = 0, X = 1)) {
    Y := 1
  } else {
    Y := [interpreter](source.(X-1)) + [interpreter](source.(X-2))
  }
} write Y
\end{verbatim}

\subsection{How this translates into logic}
The notion of computability is closely related to that of decidability in 
logic. A statement is \emph{decidable}\/ if either itself or its negation can be 
proven. For many years, it was thought that given a set of axioms strong 
enough every statement in mathematics was decidable, but as we will 
see, that is not the case.

Without going too far into formal logic, I can only say that a successful proof
of a statement can be seen as a trace of a program that finds the statement
from the axioms. The other direction is true as well: A program can be
understood as a description of a constructive proof,\footnote{This equivalence
goes extremely deep, see Curry-Howard correspondence, see
\cite{girard1989proofs} for a thorough introduction to proofs as programs.}.
In short: Formal logic (over the natural numbers) is Turing complete!

Since a proof is nothing but a finite string of symbols, we can code it as a
natural number. But since the domain, on which we use formal logic is natural
numbers, this also means that we can produce predicates about other predicates,
for example {\tt the first argument is a proof of the second argument}.

This is where the recursion theorem comes in: According to it, and this is a 
bit informal, since first, we'd need to translate it into its logical 
equivalent, every predicate can assume, that its first argument is the coding 
of itself.

Then what happens, if we apply this to the predicate {\tt "no number codes a proof 
of the first argument"}? We'd have that {\tt "no number codes a proof of this
statement"}. Assume that it is false, then there \emph{is}\/ a proof for the 
statement, but since the statement is false, we'd have a contradiction in our 
formal system. And if the statement is true? Then there is a true statement 
expressable in the system, that can not be proven. This is known as \emph{GÃ¶del's 
incompleteness theorem}.