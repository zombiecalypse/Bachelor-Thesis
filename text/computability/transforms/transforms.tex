\section{Language Transforms\timeestimation{25h}} % (fold)
\label{sec:transforms}
In this chapter, we'll discuss how we can use the notion of a data 
representation of a program to get a standard toolchain.
\subsection{Language Subsets} % (fold)
\label{sub:Language Subsets}
\begin{defn}
	Let {\tt A} and {\tt B} be two languages such that each valid {\tt B} 
	program is also a valid {\tt A} program. Further 
	$\forall b\in B\, \forall d\in Dat(B): \interpret[A]{b}(d) = \interpret[B]{b}(d)$

	Then $B$ is a language subset of $A$ (and conversely $A$ is a superset of
	$B$), writen $B \subset A$.
\end{defn}
\paragraph{{\tt C++}  and {\tt C} } % (fold)
\label{par:Cpp and C}
{\tt C++} was designed to be a object-oriented superset to the popular {\tt C}
programming language, so that the new {\tt C++} code could use legacy {\tt C}
code without modification. This notion was important to raise the acceptance of
{\tt C++} with programmers and eased switching.
% paragraph Cpp and C (end)
% subsection Language Subsets (end)
\subsection{Interpreter} % (fold)
\label{sub:Interpreter}
Today programmers and machines seldom speak the same language. Programming in 
machine language is difficult, error-prone and unportable to name only a few 
drawbacks. However it seems reasonable to expect to be able to execute ones 
code nonetheless. Typically, we want our computer to interpret what we mean 
in our high-level programming language. An {\em interpreter} is such a program.

\begin{defn}
	An {\em interpreter} of $A$ is a program $interp$ such that
	\begin{equation*}
		\begin{split}
			\interpret[P]{interp}&: A \times \Input[A] \longrightarrow \Output[A] \\
			\interpret[P]{interp}&(a, d) = \interpret[A]{a}(d)
		\end{split}
	\end{equation*}
\end{defn}

An interpreter typically parses the program code to a Abstract Syntax Tree 
(AST), in which the relations of the statements can easily be infered. For 
example, the AST of

\begin{verbatim}
	unary_length read X {
	  Y := nil
	  FOR Z IN X {
	    Y := cons nil Y
	  }
	} write Y
\end{verbatim}

might look like

\begin{verbatim}
	(PROCEDURE unary_length X Y
	  (
	    (ASSIGN Y nil)
	    (FOR Z X
	      (ASSIGN Y (cons nil (VAR Y)))
	    )
	  )
	)
\end{verbatim}

Since parsing is not part of this text, we will assume, that a convenient 
format is already given.\footnote{If you are interested in the whole story, 
	\cite{aho2007compilers} offers a good introduction into the theory and the 
	appendix \ref{sec:implementingWhile} explains how the implementation of 
\WHILE works.}

What does it mean, if we can express an interpreter for $A$ in the language 
$B$? It means, that we can solve any problem in $B$ using a program in $A$, 
in the worst case using an interpreter. This allows us to classify languages 
in the following way.

\begin{defn}
	The language $A$ is {\em at least as powerful} as $B$, if there is an 
	interpreter for $B$ in $A$.

	Similarly, $A$ are {\em equally powerful} if $A$ can interpret $B$ and vice versa.
\end{defn}

Interpreters are typically the first step in implementing a language: they 
are relatively easy to write and therefore allow experimenting. The downside 
is that working on the AST and constantly translating typically takes longer 
than an equivalent $A$ program would take. This {\em overhead} is often 
just a fixed factor, but that factor could be 100, making the interpreted program a 
hundred times slower than the native one.

\lineofthought{Python, Ruby, ... are languages, that only offer interpretation}
% subsection Interpreter (end)
\subsection{Compiler} % (fold)
\label{sub:Compiler}
\lineofthought{
	\begin{itemize}
		\item Simple definition: language transformer.
		\item 3 stages: frontend, independent middle and backend.
	\end{itemize}
}
\paragraph{How the {\tt gcc} is ported} % (fold)
\label{par:gcc}
When a new machine architecture is build, there is the problem that there is 
not yet any compiler for it. The na√Øve solution would be to write a complete 
compiler in the new machine language, but that would be very cumbersome and 
inefficient to do that for every new processor build.

There are two parts to the problem: on one hand, there is not any compiler, 
that outputs the new machine lanugage and on the other hand, there is no 
compiler that runs on the new machines.

For the first problem, we see that of the three stages of a modern compiler,
only the backend really depends on the output language. Often the backend has 
a general variant that can be parametrized for many architectures.
\footnote{For the whole process of writing a {\tt gcc} backend, see \cite{nilsson2000porting}}

The second problem is nowadays solved by cross-compiling -- when the language 
the compiler is executed in and the output language differ. Another approach 
was to have a minimal (non-optimizing) compiler or an interpreter to do the 
first translation.
% paragraph How the gcc is ported (end)
% subsection Compiler (end)
\subsection{Futamura Projections} % (fold)
\label{sub:Futamura}
\subsubsection{Specializer} % (fold)
\label{ssub:Specializer}
\subsubsection{Futamura Projections} % (fold)
\label{ssub:Futamura Projections}
The notion of a specializer as a transformer of source code has lead to some 
interesting observations: \lineofthought{ 
	\begin{itemize}
		\item An interpreter spec'ed with source is executable ($\rightarrow$ 
			py2exe) 
			\begin{equation*}
			  \begin{split}
					\interpret[P]{\interpret[P]{spec}(interp_A, src)}(d) 
						&= \interpret[P]{interp_A}(src,d)\\
						&= \interpret[A]{src}(d)
			  \end{split}
			\end{equation*}
		\item A compiler is a specialized specializer with the step above.
			\begin{equation*}
			  \begin{split}
					\interpret[P]{\interpret[P]{spec}(spec, interp_A}(src)
						&= \interpret[P]{spec}(interp_A, src)
			  \end{split}
			\end{equation*}
		\item Repeat to get a compiler generator.
	\end{itemize} 
	Use types to visualize (
	$\interpret[P]{spec}: Input_1 \rightarrow \coded{\left( Input_2 \rightarrow Output \right)}$)
}

\lineofthought{
	Exercise: interpreter for {\tt while} is given. Make a compiler.
}

% subsubsection Futamura Projections (end)
\paragraph{The PyPy project} % (fold)
\label{par:The PyPy project}
\begin{example}
	The {\tt PyPy} project is an attempt to implement the popular {\tt
	Python}\footnote{\url{http://python.org/}} itself in a subset of {\tt Python}
	(called {\tt RPython}). Since {\tt Python} is an interpreted language, it
	would seem that this approach would lead to very slow execution, but that is
	not the case: PyPy uses Just-In-Time (JIT) specialization and compilation
	techniques in part described in \cite{psycho}.

	While the approach described in \ref{ssub:Specializer} is understood to be 
	executed before the actual program is run, it is also possible to run it 
	in parallel to the actual computation: Now the specializer can use 
	statistical information on the values. For example, while it might not be 
	obvious from the source that a certain value is constant and therefore a 
	static specializer might fail to set in, but a dynamic specializer can 
	determine this and produce a specialized function to call.

	For a highly dynamic language like {\tt Python}, it can lead to a hundredfold 
	speedup for very repetitive arithmetics\footnote{\cite{psycho}}.
\end{example}

% paragraph The PyPy project (end)

% subsubsection Specializer (end)
% subsection Futamura (end)
